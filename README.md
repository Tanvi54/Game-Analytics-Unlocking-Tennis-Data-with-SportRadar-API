# ğŸ† SportRadar Data Analysis & Dashboard Project

## ğŸ“˜ Overview
This project implements a **complete data engineering and analytics pipeline** for sports data from the SportRadar dataset.  
It covers everything from **data ingestion (JSON)** â†’ **ETL to MySQL** â†’ **SQL analytics** â†’ **interactive dashboard visualization (Streamlit)**.  

---

## ğŸ¯ Project Objectives
- âœ… Extract structured data from complex JSON files  
- âœ… Build an automated ETL process using Python + MySQL  
- âœ… Perform SQL-based analytics and generate insights  
- âœ… Visualize data through an interactive Streamlit dashboard  

---

## ğŸ“‚ Project Structure
```bash
sportradar-project/
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ app.py                     # Streamlit dashboard for analytics & visualization
â”‚   â”œâ”€â”€ fetch_competitions.py      # Fetch & transform competitions data from JSON
â”‚   â”œâ”€â”€ fetch_complexes.py         # Fetch & transform complexes data from JSON
â”‚   â”œâ”€â”€ fetch_doubles_rankings.py  # Fetch & transform doubles rankings data
â”‚   â”œâ”€â”€ load_to_mysql.py           # ETL script to load transformed data into MySQL
â”‚   â”œâ”€â”€ run_queries.py             # Executes SQL analysis queries automatically
â”‚   
â”œâ”€â”€ sample_json/
â”‚       â”œâ”€â”€ competitions.json      # Raw competitions data
â”‚       â”œâ”€â”€ complexes.json         # Raw complexes data
â”‚       â””â”€â”€ doubles_rankings.json  # Raw player rankings data
â”‚
â”œâ”€â”€ .env                           # Environment variables (DB credentials, API key)
â”œâ”€â”€ requirements.txt               # All Python dependencies
    
```


---

## ğŸ§  Data Sources
This project uses **three JSON data files** (`sample_json/`) as input:  
- ğŸ `competitions.json` â€” competition and category info  
- ğŸŸï¸ `complexes.json` â€” complexes and venues info  
- ğŸ§â€â™‚ï¸ `doubles_rankings.json` â€” player stats and rankings  

After transformation, six relational tables are created in **MySQL**:

| Table Name | Description |
|-------------|-------------|
| `categories` | Derived from competition data |
| `competitions` | Sports competitions and metadata |
| `complexes` | Details of sports complexes |
| `venues` | Venue information with location details |
| `competitors` | Player / team information |
| `competitor_rankings` | Ranking and performance metrics |

---

## âš™ï¸ Setup Instructions

1ï¸âƒ£ Clone and Open the Project
```bash
git clone <your-repository-url>
cd sportradar-project
```

2ï¸âƒ£ Create a Virtual Environment
```bash
Copy code
python -m venv venv
venv\Scripts\activate       # (Windows)
source venv/bin/activate    # (Mac/Linux)
```

3ï¸âƒ£ Install Dependencies
```bash
Copy code
pip install -r requirements.txt
```

4ï¸âƒ£ Configure Environment Variables
Create a .env file in the root directory:

```bash
Copy code
SPORTRADAR_API_KEY = yourapikeyhere
DATABASE_URL= mysql+pymysql://root:password@localhost/sport_radar   # ğŸ” replace with your actual MySQL password
```

ğŸ§© Step 1 â€” Create Tables in MySQL
Run the schema file to set up tables

ğŸ§© Step 2 â€” Load Data into MySQL
Execute the ETL script to populate all tables:

```bash
Copy code
python etl/load_to_mysql.py
```

âœ… This will:

- Drop existing tables safely

- Recreate new schema

- Load parsed JSON data

- Confirm row counts inserted

ğŸ§© Step 3 â€” Run Analytical SQL Queries
You can execute queries directly from MySQL Workbench Or run all predefined queries from Python:

```bash
Copy code
python etl/run_queries.py
```

ğŸ§© Step 4 â€” Launch Streamlit Dashboard
Run the Streamlit app for interactive exploration:

```bash
Copy code
cd etl
streamlit run app.py
```
Then open the provided localhost link (e.g., http://localhost:8501) in your browser.

ğŸ–¥ï¸ Streamlit Dashboard Features
- ğŸ  Homepage Dashboard
   - Total number of competitors

   - Number of countries represented

   - Highest points scored by a competitor


ğŸ” Competitor Search & Filter
- Search competitors by name

- Filter by rank range, country, or points threshold


ğŸ§¾ Competitor Details Viewer

- Displays details such as:

    - Rank position

    - Movement

    - Competitions played

    - Country


ğŸŒ Country-Wise Analysis
- List of countries with:

    - Total competitors

    - Average points


ğŸ† Leaderboards
- Displays top-ranked competitors

- Highest points scorers


ğŸ§¾ SQL Analysis Highlights
- ğŸ Competitions Analysis
    - Count competitions by category

    - Filter by competition type (e.g., doubles)

    - Identify parent and sub-competitions


- ğŸŸï¸ Venue Analysis
    - Venues by complex

    - Venues grouped by country

    - Complexes with multiple venues


- ğŸ§â€â™‚ï¸ Competitor Analysis
    - Top 5 ranked competitors

    - Competitors with stable ranks

    - Country-wise performance and points distribution


ğŸ“Š Example Key Metrics (Dashboard Cards)
| Metric | Description |
|-------------|-------------|
| ğŸ§ Total Competitors | 1,000 |
| ğŸŒ Countries Represented| 80 |
| Highest Points | 12,300 |
| âš–ï¸ Average Rank Movement | Â±2 |



ğŸ“ˆ Technologies Used
| Category | Tools |
|-------------|-------------|
| Programming Language | Python 3.9+ |
| Database | MySQL Workbench |
| Visualization | Streamlit, Plotly |
| ETL | SQLAlchemy, Pandas |
| Environment Management| python-dotenv |
| Libraries | mysql-connector-python, pymysql |


ğŸ¥ Demo Walkthrough
- Run ETL: python etl/load_to_mysql.py

- Verify Tables: Using MySQL Workbench

- Execute Queries: SOURCE queries.sql

- Launch Dashboard: streamlit run app.py

- Explore: Interactive leaderboards, country filters, and insights

ğŸ§¾ Requirements
```bash
Copy code
streamlit
pandas
sqlalchemy
pymysql
mysql-connector-python
plotly
python-dotenv
```
